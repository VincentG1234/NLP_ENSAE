# ğŸ§  NLP ENSAE â€“ Query Rewriting Pipeline

This project provides a full pipeline for rewriting search queries to improve performance in retrieval systems (e.g., search engines, RAG). It includes:

- Synthetic data generation from public datasets (MS MARCO, Natural Questions, etc.)
- LLM-based query rewriting using Groq-hosted APIs or Hugging Face pipelines
- Fine-tuning of Flan-T5 models (with or without LoRA)
- Knowledge distillation from teacher to student models
- Evaluation, logging, and artifact tracking using Weights & Biases (W&B)

---

## ğŸ“ Project Structure

Directory structure:
â””â”€â”€ vincentg1234-nlp_ensae.git/
    â”œâ”€â”€ README.md
    â”œâ”€â”€ NB_analysis_data.ipynb
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ data_engineering/
    â”‚   â”œâ”€â”€ load_data_hf.py
    â”‚   â”œâ”€â”€ noise_queries.py
    â”‚   â””â”€â”€ write_refined_queries_api_call.py
    â”œâ”€â”€ data_folder/
    â”‚   â”œâ”€â”€ paired_queries.csv
    â”‚   â”œâ”€â”€ paired_queries_test.csv
    â”‚   â”œâ”€â”€ paired_queries_train.csv
    â”‚   â”œâ”€â”€ raw_queries.csv
    â”‚   â””â”€â”€ refined_queries.csv
    â”œâ”€â”€ fine_tuning/
    â”‚   â”œâ”€â”€ distillation.py
    â”‚   â”œâ”€â”€ finetunning_T5.py
    â”‚   â””â”€â”€ finetunning_T5_LORA.py
    â””â”€â”€ test/
        â”œâ”€â”€ test_distill.py
        â””â”€â”€ test_predictions_distilled.csv



## ğŸš€ Training Commands

**Standard fine-tuning**

```bash
python finetunning_T5.py
```


**LoRA fine-tuning**
```bash
python finetunning_T5_LORA.py
```

**Distillation**
```bash
python distillation.py
```


## ğŸ“Š Dataset Files

- raw_queries.csv â€“ Raw queries from HF datasets
- refined_queries.csv â€“ Rewritten by LLMs
- paired_queries.csv â€“ Noisy + refined aligned
- paired_queries_train.csv, paired_queries_test.csv â€“ Train/test splits
